{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Anime Face Generation\n",
    "In the final project, you'll learn to define and train a GAN on a dataset of anime faces. The goal is to obtain a generator network to generate images of anime faces that look very cute and cartoon!\n",
    "\n",
    "The final project includes several tasks, from loading data and training a GAN. At the end of the notebook, you will be able to visualize the results of the trained generator to understand its performance; the samples you generate should look like fairly anime faces with a small amount of noise.\n",
    "\n",
    "**In this project, we encourage students to think about how to improve the performance of GAN and the stability of training. Students can write the experimental results and analysis into the report. This part will be used as a bonus item.**\n",
    "\n",
    "\n",
    "\n",
    "## Download the data\n",
    "You can use this link [Anime Face dataset](https://www.kaggle.com/lunarwhite/anime-face-dataset-ntumlds) to download dataset for training your adversarial networks.\n",
    "\n",
    "This is an dataset consisting of 36.7k high-quality anime faces. We suggest that you utilize a GPU for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import torch, torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "def show_images(images, nmax=64):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(make_grid(denorm(images.cpu().detach()[:nmax]), nrow=8).permute(1, 2, 0))\n",
    "# define your own dataset address:\n",
    "images = './dataset/images/'   #  36740 images\n",
    "images2 = './dataset/images2/' #  63565 images\n",
    "out2 ='./dataset/out2/'        #  25663 images\n",
    "rem1 = './dataset/rem1/'       #  725 images\n",
    "rem2 = './dataset/rem2/'       #  1000 images\n",
    "testB = './dataset/testB/'     #  100 images\n",
    "trainB = './dataset/trainB/'   #  3400 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Seeds:\n",
    "seed = 1025\n",
    "torch.manual_seed(seed)\n",
    "gen = torch.Generator()\n",
    "gen.manual_seed(seed) # to keep shuffle persistent\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pre-process and Load the Data\n",
    "Based on the previous knowledge, students are required to complete the code for preprocessing and data loading. \n",
    "### For preprocessing \n",
    "we recommend students to use `transforms` in `torchvision`. Students are required to fill in at least two items: `Resize` and `CenterCrop`. Students can also try other **data augumentation methods** and display the results in the final report as a **bonus item**.\n",
    "### Load the Data\n",
    "In this part, you need define your own `Dataset` to load training images. For GAN, you don't need to load label data. Thus, defining the Dataset is easier than previous assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import xfunction.transforms\n",
    "from PIL import Image\n",
    "importlib.reload(xfunction.transforms)\n",
    "#TODO: Create your own Preprocessing methods\n",
    "#The batch_size is defined by yourself based on the memory of GPU or CPU.\n",
    "batch_size = 128\n",
    "num_workers = 8\n",
    "# i1 : (0.59441761, 0.59492202, 0.69361376), (0.2217842,  0.2510431,  0.2462906)\n",
    "# i2 : (0.57181897, 0.58783819, 0.68684787), (0.24488547, 0.26629325, 0.25519701)\n",
    "# ic : (0.58009647, 0.59043287, 0.6893261 ), (0.23642387, 0.26070738, 0.25193475)\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "transform = transforms.Compose([\n",
    "                                #\n",
    "                                transforms.Resize(64),\n",
    "                                transforms.CenterCrop(64),\n",
    "                                #\n",
    "                                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                #\n",
    "                                transforms.RandomApply(\n",
    "                                    [transforms.RandomChoice(\n",
    "                                        [transforms.ColorJitter((0.8,1.0),  # brightness\n",
    "                                                           (0.8,1.2),#(0.8,1.5), # contrast\n",
    "                                                           (0.6,1.4),#(0.6,1.8), # saturation\n",
    "                                                           (-0.1,0.1)), # hue\n",
    "                                        transforms.RandomEqualize(1.0),\n",
    "                                        #transforms.RandomGrayscale(1.0),\n",
    "                                        ], p=[0.65,0.3,]) #p=[0.8, 0.19, 0.01]) # probabilities of each transform from list above\n",
    "                                    ], p = 1.0), # probability of any of the transforms above being applied\n",
    "#\n",
    "                                xfunction.transforms.EnhanceBrightness(1.0, 1.1, 0.2), # intensity , max_brightness, probab\n",
    "                                #\n",
    "                                transforms.RandomApply([\n",
    "                                    transforms.RandomChoice([transforms.CenterCrop(62),transforms.CenterCrop(60),transforms.CenterCrop(58),transforms.CenterCrop(56),\n",
    "                                                             transforms.CenterCrop(54)]\n",
    "                                                             , p = [0.2,0.2,0.2,0.2,0.2]),\n",
    "                                    transforms.Resize(64)], p = 0.5),\n",
    "                                #\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(*stats)])\n",
    "def denorm(img_tensors):\n",
    "    return img_tensors * stats[1][0] + stats[0][0]\n",
    "\n",
    "#TODO: Complete the loading data including Dataset and Dataloader.\n",
    "import os\n",
    "import cv2\n",
    "class AnimeData(Dataset):\n",
    "    \"\"\"\n",
    "    Wrap the data into a Dataset class, and then pass it to the DataLoader\n",
    "    :__init__: Initialization data\n",
    "    :__getitem__: support the indexing such that dataset[i] can be used to get ith sample\n",
    "    :__len__: return the size of the dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, roots, transform=None):\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        # Load the image paths:\n",
    "        self.images = []\n",
    "        for root in roots:\n",
    "            for img_name in os.listdir(root):\n",
    "                if os.path.isfile(root+img_name) and img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    self.images.append(root+img_name)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #img = cv2.imread(self.images[index])\n",
    "        img = Image.open(self.images[index])\n",
    "        return self.transform(img.convert(\"RGB\"))\n",
    "\n",
    "    def calculate_mean_std(self):\n",
    "        if self.mean is None or self.std is None:\n",
    "            self.mean = 0.0\n",
    "            self.std = 0.0\n",
    "            for img in self.images:\n",
    "                img = cv2.imread(img)\n",
    "                self.mean += np.mean(img,axis=(0,1))\n",
    "                self.std +=np.std(img,axis=(0,1))\n",
    "            self.mean /= len(self.images) * 255\n",
    "            self.std /= len(self.images) * 255\n",
    "        return self.mean, self.std\n",
    "\n",
    "\n",
    "#TODO: Complete the trainloader \n",
    "trainset = AnimeData([images],transform) #, images2, out2, rem1, rem2, testB, trainB]\n",
    "trainloader = DataLoader(trainset, batch_size, shuffle=True, num_workers=num_workers, generator=gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Visualize the input image\n",
    "Note that these are color images with 3 color channels (RGB) each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#Show first batch of images from trainloader:\n",
    "show_images(next(iter(trainloader)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Check your device and move data to device\n",
    "In this part, students can check whether the computer's GPU is available and move the data to the GPU (or CPU). We strongly recommend that students use GPU to speed up the program.\n",
    "\n",
    "`torch.cuda.is_available` can help us to check whether GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define a GAN\n",
    "A GAN consists of two adversarial networks, a discriminator and a generator.\n",
    "### Discriminator\n",
    "Your first task will be to define the discriminator. This is a convolutional classifier like you've built before, only without any maxpooling layers. \n",
    "#### Exercise: Complete the Discriminator class\n",
    "* The inputs to the discriminator are 3x64x64 tensor images\n",
    "* The output should be a single value that will indicate whether a given image is real or fake\n",
    "\n",
    "An example of our discriminant model is as follows, and students can also define it by themselves, including adjusting the model structure and activation function. We recommend that students use `nn.Sequential` to define the model, which is more simple and intuitive.\n",
    "\n",
    "**Students can build models based on examples, but we suggest you try different models (including model structure and activation function). This will be regared as a bonus.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    # custom weights initialization called on generator and discriminator\n",
    "    # randomly initialized from a Normal distribution with mean=0, stdev=0.02\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Create your Discriminator model\n",
    "#class Discriminator(nn.Module):\n",
    "#    def __init__(self,inchannels):\n",
    "#        super(Discriminator,self).__init__()\n",
    "#        \"\"\"\n",
    "#        Initialize the Discriminator Module\n",
    "#        :param inchannels: The depth of the first convolutional layer\n",
    "#        \"\"\"\n",
    "#        self.cnn1 = nn.Sequential(\n",
    "#            # in: inchannels (3) x 64 x 64\n",
    "#            nn.Conv2d(in_channels=inchannels, out_channels=64, kernel_size=4,stride=2, padding=1, bias=False),\n",
    "#            nn.BatchNorm2d(64),\n",
    "#            nn.LeakyReLU(0.2, inplace=True),\n",
    "#            # out: 64 x 32 x 32\n",
    "#        )\n",
    "#        self.cnn2 = nn.Sequential(\n",
    "#            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4,stride=2, padding=1, bias=False),\n",
    "#            nn.BatchNorm2d(128),\n",
    "#            nn.LeakyReLU(0.2, inplace=True),\n",
    "#            # out: 128 x 16 x 16\n",
    "#        )\n",
    "#        self.cnn3 = nn.Sequential(\n",
    "#            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4,stride=2, padding=1, bias=False),\n",
    "#            nn.BatchNorm2d(256),\n",
    "#            nn.LeakyReLU(0.2, inplace=True),\n",
    "#            # out: 256 x 8 x 8\n",
    "#        )\n",
    "#        self.cnn4 = nn.Sequential(\n",
    "#            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4,stride=2, padding=1, bias=False),\n",
    "#            nn.BatchNorm2d(512),\n",
    "#            nn.LeakyReLU(0.2, inplace=True),\n",
    "#            # out: 512 x 4 x 4\n",
    "#        )\n",
    "#        self.cnn5 = nn.Sequential(\n",
    "#            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4,stride=2, padding=1, bias=False),\n",
    "#            nn.BatchNorm2d(1024),\n",
    "#            nn.LeakyReLU(0.2, inplace=True),\n",
    "#            # out: 1024 x 2 x 2\n",
    "#        )\n",
    "#        self.cnn6 = nn.Sequential(\n",
    "#            nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=4,stride=2, padding=1, bias=False),\n",
    "#            nn.Flatten(),\n",
    "#            nn.Sigmoid(),\n",
    "#            # out: 1 x 1 x 1\n",
    "#        )\n",
    "#       #self.fc = nn.Sequential(\n",
    "#       #    nn.Linear(in_features=128,out_features=1),\n",
    "#       #    nn.Flatten(),\n",
    "#       #    nn.Sigmoid(),\n",
    "#       #    # out: 1 x 1 x 1\n",
    "#       #)\n",
    "#\n",
    "#    def forward(self,x):\n",
    "#        \"\"\"\n",
    "#        Forward propagation of the neural network\n",
    "#        :param x: The input to the neural network\n",
    "#        :return: Discriminator logits; the output of the neural network\n",
    "#        \"\"\"\n",
    "#        x = self.cnn1(x)\n",
    "#        x = self.cnn2(x)\n",
    "#        x = self.cnn3(x)\n",
    "#        x = self.cnn4(x)\n",
    "#        x = self.cnn5(x)\n",
    "#        x = self.cnn6(x)\n",
    "#        #x = self.fc(x)\n",
    "#        return x\n",
    "\n",
    "class DiscriminatorSimple(nn.Module):\n",
    "    def __init__(self,inchannels):\n",
    "        super(DiscriminatorSimple,self).__init__()\n",
    "        \"\"\"\n",
    "        Initialize the Discriminator Module\n",
    "        :param inchannels: The depth of the first convolutional layer\n",
    "        \"\"\"\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            # in: inchannels(3) x 64 x 64\n",
    "            nn.Conv2d(in_channels=inchannels, out_channels=64, kernel_size=4,stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # out: 64 x 32 x 32\n",
    "        )\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4,stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # out: 128 x 16 x 16\n",
    "        )\n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4,stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # out: 256 x 8 x 8\n",
    "        )\n",
    "        self.cnn4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4,stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # out: 512 x 4 x 4\n",
    "        )\n",
    "        self.cnn5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4,stride=1, padding=0, bias=False),\n",
    "            nn.Flatten(),\n",
    "            nn.Sigmoid(),\n",
    "            # out: 1 x 1 x 1\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param x: The input to the neural network\n",
    "        :return: Discriminator logits; the output of the neural network\n",
    "        \"\"\"\n",
    "        x = self.cnn1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = self.cnn3(x)\n",
    "        x = self.cnn4(x)\n",
    "        x = self.cnn5(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "discriminator=DiscriminatorSimple(3).to(device)\n",
    "discriminator.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generator\n",
    "\n",
    "The generator should upsample an input and generate a *new* image of the same size as our training data `3x64x64`. This should be mostly transpose convolutional layers `nn.ConvTranspose2d` with normalization applied to the outputs.\n",
    "\n",
    "#### Exercise: Complete the Generator model\n",
    "* The inputs to the generator are vectors of some length `latent_size`\n",
    "* The output should be a image of shape `3x64x64`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Create your Generator model\n",
    "latent_size = 128\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,latent_size):\n",
    "        super(Generator,self).__init__()\n",
    "        \"\"\"\n",
    "        Initialize the Generator Module\n",
    "        :param latent_size: The length of the input latent vector\n",
    "        \"\"\"\n",
    "        #self.fc = nn.Sequential(\n",
    "        #    nn.Flatten(1,-1),\n",
    "        #    nn.Linear(in_features=latent_size,out_features=256),\n",
    "        #    nn.BatchNorm1d(256),\n",
    "        #    nn.ReLU(),\n",
    "        #    nn.Unflatten(1,(256,1,1)),\n",
    "        #    # out: 1 x 1 x 1\n",
    "        #)\n",
    "        self.cnnT1 = nn.Sequential(\n",
    "            # in: 512 x 1 x 1\n",
    "            nn.ConvTranspose2d(in_channels=latent_size,out_channels=1024,kernel_size=2,stride=1,padding=0),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # out: 1024 x 2 x 2\n",
    "        )\n",
    "        self.cnnT2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=1024,out_channels=512,kernel_size=4,stride=2,padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # out: 256 x 4 x 4\n",
    "        )\n",
    "        self.cnnT3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=4,stride=2,padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # out: 256 x 8 x 8\n",
    "        )\n",
    "        self.cnnT4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=4,stride=2,padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # out: 128 x 16 x 16\n",
    "        )\n",
    "        #self.cnnT4b = nn.Sequential(\n",
    "        #    nn.ConvTranspose2d(in_channels=128,out_channels=128,kernel_size=1,stride=1,padding=0, bias=False),\n",
    "        #    nn.BatchNorm2d(128),\n",
    "        #    nn.ReLU(inplace=True),\n",
    "        #    # out: 128 x 16 x 16\n",
    "        #)\n",
    "        self.cnnT5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=4,stride=2,padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # out: 64 x 32 x 32\n",
    "        )\n",
    "        #self.cnnT5b = nn.Sequential(\n",
    "        #    nn.ConvTranspose2d(in_channels=64,out_channels=64,kernel_size=1,stride=1,padding=0, bias=False),\n",
    "        #    nn.BatchNorm2d(64),\n",
    "        #    nn.ReLU(inplace=True),\n",
    "        #    # out: 64 x 32 x 32\n",
    "        #)\n",
    "        self.cnnT6 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=64,out_channels=3,kernel_size=4,stride=2,padding=1, bias=False),\n",
    "            nn.Tanh(),\n",
    "            # out: 3 x 64 x 64\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param x: The input to the neural network     \n",
    "        :return: A 3x64x64 Tensor image as output\n",
    "        \"\"\"\n",
    "        #x = self.fc(x)\n",
    "        x = self.cnnT1(x)\n",
    "        x = self.cnnT2(x)\n",
    "        x = self.cnnT3(x)\n",
    "        x = self.cnnT4(x)\n",
    "        #x = self.cnnT4b(x)\n",
    "        x = self.cnnT5(x)\n",
    "        #x = self.cnnT5b(x)\n",
    "        x = self.cnnT6(x)\n",
    "        return x\n",
    "\n",
    "#class GeneratorSimple(nn.Module):\n",
    "#    def __init__(self,latent_size):\n",
    "#        super(GeneratorSimple,self).__init__()\n",
    "#        \"\"\"\n",
    "#        Initialize the Generator Module\n",
    "#        :param latent_size: The length of the input latent vector\n",
    "#        \"\"\"\n",
    "#        self.cnnT1 = nn.Sequential(\n",
    "#            # in: latent_size (128) x 1 x 1\n",
    "#            nn.ConvTranspose2d(in_channels=latent_size,out_channels=512,kernel_size=4,stride=1,padding=0, bias=False),\n",
    "#            nn.BatchNorm2d(512),\n",
    "#            nn.ReLU(inplace=True),\n",
    "#            # out: 512 x 4 x 4\n",
    "#        )\n",
    "#        self.cnnT2 = nn.Sequential(\n",
    "#            nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=4,stride=2,padding=1, bias=False),\n",
    "#            nn.BatchNorm2d(256),\n",
    "#            nn.ReLU(inplace=True),\n",
    "#            # out: 256 x 8 x 8\n",
    "#        )\n",
    "#        self.cnnT3 = nn.Sequential(\n",
    "#            nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=4,stride=2,padding=1, bias=False),\n",
    "#            nn.BatchNorm2d(128),\n",
    "#            nn.ReLU(inplace=True),\n",
    "#            # out: 128 x 16 x 16\n",
    "#        )\n",
    "#        self.cnnT4 = nn.Sequential(\n",
    "#            nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=4,stride=2,padding=1, bias=False),\n",
    "#            nn.BatchNorm2d(64),\n",
    "#            nn.ReLU(inplace=True),\n",
    "#            # out: 64 x 32 x 32\n",
    "#        )\n",
    "#        self.cnnT5 = nn.Sequential(\n",
    "#            nn.ConvTranspose2d(in_channels=64,out_channels=3,kernel_size=4,stride=2,padding=1, bias=False),\n",
    "#            nn.Tanh(),\n",
    "#            # out: 3 x 64 x 64\n",
    "#        )\n",
    "#    def forward(self,x):\n",
    "#        \"\"\"\n",
    "#        Forward propagation of the neural network\n",
    "#        :param x: The input to the neural network\n",
    "#        :return: A 3x64x64 Tensor image as output\n",
    "#        \"\"\"\n",
    "#        x = self.cnnT1(x)\n",
    "#        x = self.cnnT2(x)\n",
    "#        x = self.cnnT3(x)\n",
    "#        x = self.cnnT4(x)\n",
    "#        x = self.cnnT5(x)\n",
    "#        return x\n",
    "        \n",
    "generator=Generator(latent_size).to(device)\n",
    "generator.apply(weights_init)\n",
    "# random latent tensors\n",
    "noise = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
    "#TODO: use generator model to generate fake image \n",
    "fake_images = generator(noise)\n",
    "print(fake_images.shape)\n",
    "#TODO: visualize the fake images by function show_images\n",
    "show_images(fake_images.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Discriminator and Generator Losses\n",
    "\n",
    "Now we need to calculate the losses for both types of adversarial networks.\n",
    "\n",
    "### Discriminator Losses\n",
    "\n",
    "> * For the discriminator, the total loss is the sum of the losses for real and fake images, `d_loss = d_real_loss + d_fake_loss`. \n",
    "* Remember that we want the discriminator to output 1 for real images and 0 for fake images, so we need to set up the losses to reflect that.\n",
    "\n",
    "\n",
    "### Generator Loss\n",
    "\n",
    "The generator loss will look similar only with flipped labels. The generator's goal is to get the discriminator to *think* its generated images are *real*.\n",
    "\n",
    "#### Exercise: Complete real and fake loss functions\n",
    "\n",
    "**You may choose to use either cross entropy or a least squares error loss to complete the following `real_loss` and `fake_loss` functions. We also encourage students to use the loss function in other related papers as a bonus item. If you use it, please include a citation in the report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODOï¼šComplete the loss function for training GAN\n",
    "#real_loss_function = nn.BCELoss()\n",
    "#fake_loss_function = nn.BCELoss()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "positive_labels_batch=torch.ones((batch_size, 1)).to(device)\n",
    "negative_labels_batch=torch.zeros((batch_size, 1)).to(device)\n",
    "\n",
    "def calculate_loss(preds, target):\n",
    "    '''\n",
    "       Calculates how close discriminator outputs are to being real\n",
    "       or how close discriminator outputs are to being fake.\n",
    "       param, D_out: discriminator logits\n",
    "       return: real loss\n",
    "    '''\n",
    "    labels = None\n",
    "    match target:\n",
    "        case 0:\n",
    "            labels = negative_labels_batch if len(preds) == batch_size else torch.zeros((len(preds), 1)).to(device)\n",
    "        case 1:\n",
    "            labels = positive_labels_batch if len(preds) == batch_size else torch.ones((len(preds) , 1)).to(device)\n",
    "    loss = criterion(preds,labels)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optimizers\n",
    "\n",
    "#### Exercise: Define optimizers for your Discriminator (D) and Generator (G)\n",
    "\n",
    "Define optimizers for your models with appropriate hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create optimizers for the discriminator D and generator G\n",
    "#Define your learning rate'\n",
    "max_epochs = 40\n",
    "lr=0.0002\n",
    "smooth = 0.9 # smooth the discriminator loss parameter\n",
    "opt_d = torch.optim.Adam(discriminator.parameters(), lr=lr, betas = (0.5,0.999))\n",
    "opt_g = torch.optim.Adam(generator.parameters(), lr=lr, betas = (0.5,0.999))\n",
    "sched_d = torch.optim.lr_scheduler.MultiStepLR(opt_d,milestones=[25,35,45,55,65,75],gamma=0.5)\n",
    "sched_g = torch.optim.lr_scheduler.MultiStepLR(opt_g,milestones=[25,35,45,55,65,75],gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save the generated images\n",
    "This code can help you save images generated from Generator G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##Define your save path.\n",
    "sample_dir = 'generated'\n",
    "os.makedirs(sample_dir, exist_ok=True)\n",
    "def save_samples(index, latent_tensors, generator, show=True):\n",
    "    fake_images = generator(latent_tensors)\n",
    "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
    "    print('Saving', fake_fname)\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(denorm(fake_images.cpu().detach()), nrow=8).permute(1, 2, 0))\n",
    "        plt.show()\n",
    "fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training GAN to generate anime faces\n",
    "Training will involve alternating between training the discriminator and the generator. You'll use your functions `real_loss` and `fake_loss` to help you calculate the discriminator losses.\n",
    "\n",
    "* You should train the discriminator by alternating on real and fake images\n",
    "* Then the generator, which tries to trick the discriminator and should have an opposing loss function\n",
    "\n",
    "\n",
    "#### Saving Samples\n",
    "\n",
    "You've been given some code to save some generated \"fake\" samples.\n",
    "\n",
    "#### Exercise: Complete the training function\n",
    "\n",
    "Keep in mind that, if you've moved your models to GPU, you'll also have to move any model inputs to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Complete the training function\n",
    "from sklearn.metrics import accuracy_score\n",
    "losses_g = []\n",
    "losses_d = []\n",
    "real_scores = []\n",
    "fake_scores = []\n",
    "REAL_LABEL = 1\n",
    "FAKE_LABEL = 0\n",
    "\n",
    "def train(discriminator, generator, d_optimizer, g_optimizer, d_scheduler, g_scheduler, epochs=1):\n",
    "    iter_count = 0\n",
    "    start_idx=1\n",
    "    discriminator.train()\n",
    "    generator.train()\n",
    "    for epoch in range(epochs):\n",
    "        for real_images in tqdm(trainloader):\n",
    "            with torch.set_grad_enabled(True):\n",
    "                real_images=real_images.to(device)\n",
    "                real_batch_size = real_images.shape[0]\n",
    "\n",
    "                # 1. Train the discriminator on real and fake images\n",
    "                d_optimizer.zero_grad()\n",
    "\n",
    "                # Pass real images through discriminator\n",
    "                d_real_out = discriminator(real_images)\n",
    "                real_loss = calculate_loss(preds=d_real_out,target=REAL_LABEL) * smooth\n",
    "                real_score = torch.mean(d_real_out).item()\n",
    "\n",
    "                # Generate fake images\n",
    "                noise = torch.randn(real_batch_size, latent_size, 1, 1).to(device)\n",
    "                fake_images = generator(noise)\n",
    "\n",
    "                # Pass fake images through discriminator\n",
    "                d_fake_out = discriminator(fake_images)\n",
    "                fake_loss = calculate_loss(preds=d_fake_out,target=FAKE_LABEL)\n",
    "                fake_score = torch.mean(d_fake_out).item()\n",
    "\n",
    "                # Update discriminator weights\n",
    "                loss_d = real_loss + fake_loss\n",
    "                loss_d.backward()\n",
    "                d_optimizer.step()\n",
    "\n",
    "\n",
    "                ## 2. Train the generator with an adversarial loss\n",
    "                g_optimizer.zero_grad()\n",
    "\n",
    "                # Generate fake images\n",
    "                noise = torch.randn(real_batch_size, latent_size, 1, 1).to(device)\n",
    "                fake_images = generator(noise)\n",
    "\n",
    "                # Try to fool the discriminator\n",
    "                d_fake_out = discriminator(fake_images)\n",
    "                # The label is set to 1(real-like) to fool the discriminator\n",
    "                loss_g = calculate_loss(preds=d_fake_out,target=REAL_LABEL)\n",
    "\n",
    "                # Update generator weights\n",
    "                loss_g.backward()\n",
    "                g_optimizer.step()\n",
    "\n",
    "        d_scheduler.step()\n",
    "        g_scheduler.step()\n",
    "        losses_g.append(loss_g.item())\n",
    "        losses_d.append(loss_d.item())\n",
    "        real_scores.append(real_score)\n",
    "        fake_scores.append(fake_score)\n",
    "        # Log losses & scores (last batch)\n",
    "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
    "        epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
    "\n",
    "        # Save generated images\n",
    "        save_samples(epoch+start_idx, fixed_latent,generator, show=True)\n",
    "            \n",
    "        state_dis = {'dis_model': discriminator.state_dict(), 'epoch': epoch}\n",
    "        state_gen = {'gen_model': generator.state_dict(), 'epoch': epoch}\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint') \n",
    "        torch.save(state_dis, 'checkpoint/'+'D__'+str(epoch+1)) #each epoch\n",
    "        torch.save(state_gen, 'checkpoint/'+'G__'+str(epoch+1)) #each epoch\n",
    "#Train the GAN\n",
    "start_time=time.perf_counter()\n",
    "train(discriminator, generator, opt_d, opt_g, sched_d, sched_g, epochs=max_epochs)\n",
    "print(f\"Training Took {time.perf_counter()-start_time} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##Visualize your loss curve of D and G\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(losses_d, label='Discriminator', alpha=0.5)\n",
    "plt.plot(losses_g, label='Generator', alpha=0.5)\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Discriminator's scores\n",
    "plt.plot(real_scores, '-')\n",
    "plt.plot(fake_scores, '-')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('score')\n",
    "plt.legend(['Real', 'Fake'])\n",
    "plt.title('Scores');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model checkpoints\n",
    "torch.save(generator.state_dict(), 'Generator.pth')\n",
    "torch.save(discriminator.state_dict(), 'Discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "vid_fname = 'gans_training.avi'\n",
    "\n",
    "files = [os.path.join(sample_dir, f) for f in os.listdir(sample_dir) if 'generated' in f]\n",
    "files.sort()\n",
    "\n",
    "out = cv2.VideoWriter(vid_fname,cv2.VideoWriter_fourcc(*'MP4V'), 1, (530,530))\n",
    "[out.write(cv2.imread(fname)) for fname in files]\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "load = False\n",
    "#Load the last model\n",
    "if load:\n",
    "    #generator.load_state_dict(torch.load('checkpoint/G__80')['gen_model'])\n",
    "    #discriminator.load_state_dict(torch.load('checkpoint/D__80')['dis_model'])\n",
    "    generator.load_state_dict(torch.load('Generator.pth'))\n",
    "    discriminator.load_state_dict(torch.load('Discriminator.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "noise = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
    "fake_images = generator(noise)\n",
    "show_images(fake_images.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}