{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Anime Face Generation\n",
    "In the final project, you'll learn to define and train a GAN on a dataset of anime faces. The goal is to obtain a generator network to generate images of anime faces that look very cute and cartoon!\n",
    "\n",
    "The final project includes several tasks, from loading data and training a GAN. At the end of the notebook, you will be able to visualize the results of the trained generator to understand its performance; the samples you generate should look like fairly anime faces with a small amount of noise.\n",
    "\n",
    "**In this project, we encourage students to think about how to improve the performance of GAN and the stability of training. Students can write the experimental results and analysis into the report. This part will be used as a bonus item.**\n",
    "\n",
    "\n",
    "\n",
    "## Download the data\n",
    "You can use this link [Anime Face dataset](https://www.kaggle.com/lunarwhite/anime-face-dataset-ntumlds) to download dataset for training your adversarial networks.\n",
    "\n",
    "This is an dataset consisting of 36.7k high-quality anime faces. We suggest that you utilize a GPU for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import torch, torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.utils import save_image\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "%matplotlib inline\n",
    "def show_images(images, nmax=64):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(make_grid(denorm(images.detach()[:nmax]), nrow=8).permute(1, 2, 0))\n",
    "#TODO: define your own dataset address\"\n",
    "root = './images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Pre-process and Load the Data\n",
    "Based on the previous knowledge, students are required to complete the code for preprocessing and data loading. \n",
    "### For preprocessing \n",
    "we recommend students to use `transforms` in `torchvision`. Students are required to fill in at least two items: `Resize` and `CenterCrop`. Students can also try other **data augumentation methods** and display the results in the final report as a **bonus item**.\n",
    "### Load the Data\n",
    "In this part, you need define your own `Dataset` to load training images. For GAN, you don't need to load label data. Thus, defining the Dataset is easier than previous assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Create your own Preprocessing methods\n",
    "#The batch_size is defined by yourself based on the memory of GPU or CPU.\n",
    "batch_size = 128\n",
    "num_workers = 4\n",
    "stats = (0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                transforms.Resize(64),\n",
    "                                transforms.CenterCrop(64),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(*stats)])\n",
    "def denorm(img_tensors):\n",
    "    return img_tensors * stats[1][0] + stats[0][0]\n",
    "\n",
    "#TODO: Complete the loading data including Dataset and Dataloader.\n",
    "import os\n",
    "import cv2\n",
    "class AnimeData(Dataset):\n",
    "    \"\"\"\n",
    "    Wrap the data into a Dataset class, and then pass it to the DataLoader\n",
    "    :__init__: Initialization data\n",
    "    :__getitem__: support the indexing such that dataset[i] can be used to get ith sample\n",
    "    :__len__: return the size of the dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, root, transform=None):\n",
    "        # Load the image paths:\n",
    "        self.images = []\n",
    "        for img_name in os.listdir(root):\n",
    "            if os.path.isfile(root+img_name) and img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                self.images.append(root+img_name)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = cv2.imread(self.images[index])\n",
    "        return self.transform(img)\n",
    "        \n",
    "#TODO: Complete the trainloader \n",
    "trainset = AnimeData(root,transform)\n",
    "trainloader = DataLoader(trainset, batch_size, shuffle=True, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize the input image\n",
    "Note that these are color images with 3 color channels (RGB) each."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#TODOï¼šrandomly choose images to visualize - run after creating dataloader\n",
    "show_images(next(iter(trainloader)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Check your device and move data to device\n",
    "In this part, students can check whether the computer's GPU is available and move the data to the GPU (or CPU). We strongly recommend that students use GPU to speed up the program. \n",
    "\n",
    "`torch.cuda.is_available` can help us to check whether GPU is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda')\n",
    "else:\n",
    "    device=torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Define a GAN\n",
    "A GAN consists of two adversarial networks, a discriminator and a generator.\n",
    "### Discriminator\n",
    "Your first task will be to define the discriminator. This is a convolutional classifier like you've built before, only without any maxpooling layers. \n",
    "#### Exercise: Complete the Discriminator class\n",
    "* The inputs to the discriminator are 3x64x64 tensor images\n",
    "* The output should be a single value that will indicate whether a given image is real or fake\n",
    "\n",
    "An example of our discriminant model is as follows, and students can also define it by themselves, including adjusting the model structure and activation function. We recommend that students use `nn.Sequential` to define the model, which is more simple and intuitive.\n",
    "<img src=\"./arch_plan/d.png\" width=\"80%\"/>\n",
    "\n",
    "**Students can build models based on examples, but we suggest you try different models (including model structure and activation function). This will be regared as a bonus.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Create your Discriminator model\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,inchannels):\n",
    "        super(Discriminator,self).__init__()\n",
    "        \"\"\"\n",
    "        Initialize the Discriminator Module\n",
    "        :param inchannels: The depth of the first convolutional layer\n",
    "        \"\"\"\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inchannels, out_channels=64, kernel_size=4,stride=2, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=4,stride=2, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.cnn3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=4,stride=2, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.cnn4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4,stride=2, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(),\n",
    "        )\n",
    "        self.cnn5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=1, kernel_size=4,stride=1, padding=0),\n",
    "            nn.Flatten(),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param x: The input to the neural network     \n",
    "        :return: Discriminator logits; the output of the neural network\n",
    "        \"\"\"\n",
    "        x = self.cnn1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x = self.cnn3(x)\n",
    "        x = self.cnn4(x)\n",
    "        x = self.cnn5(x)\n",
    "        return x\n",
    "\n",
    "D=Discriminator(3).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generator\n",
    "\n",
    "The generator should upsample an input and generate a *new* image of the same size as our training data `3x64x64`. This should be mostly transpose convolutional layers `nn.ConvTranspose2d` with normalization applied to the outputs.\n",
    "\n",
    "#### Exercise: Complete the Generator model\n",
    "* The inputs to the generator are vectors of some length `latent_size`\n",
    "* The output should be a image of shape `3x64x64`\n",
    "\n",
    "The example of Generator is as follows. \n",
    "<img src='./arch_plan/g.png' width=80% />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Create your Generator model\n",
    "latent_size = 128\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self,latent_size):\n",
    "        super(Generator,self).__init__()\n",
    "        \"\"\"\n",
    "        Initialize the Generator Module\n",
    "        :param latent_size: The length of the input latent vector\n",
    "        \"\"\"\n",
    "        self.cnnT1 = nn.Sequential(\n",
    "            # in: latent_size (128) x 1 x 1\n",
    "            nn.ConvTranspose2d(in_channels=latent_size,out_channels=512,kernel_size=4,stride=1,padding=0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            # out: 512 x 4 x 4\n",
    "        )\n",
    "        self.cnnT2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=512,out_channels=256,kernel_size=4,stride=2,padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            # out: 256 x 8 x 8\n",
    "        )\n",
    "        self.cnnT3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=4,stride=2,padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            # out: 128 x 16 x 16\n",
    "        )\n",
    "        self.cnnT4 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=4,stride=2,padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            # out: 64 x 32 x 32\n",
    "        )\n",
    "        self.cnnT5 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=64,out_channels=3,kernel_size=4,stride=2,padding=1),\n",
    "            nn.Tanh(),\n",
    "            # out: 3 x 64 x 64\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        Forward propagation of the neural network\n",
    "        :param x: The input to the neural network     \n",
    "        :return: A 3x64x64 Tensor image as output\n",
    "        \"\"\"\n",
    "        x = self.cnnT1(x)\n",
    "        x = self.cnnT2(x)\n",
    "        x = self.cnnT3(x)\n",
    "        x = self.cnnT4(x)\n",
    "        x = self.cnnT5(x)\n",
    "        return x\n",
    "        \n",
    "G=Generator(latent_size).to(device) \n",
    "# random latent tensors\n",
    "noise = torch.randn(batch_size, latent_size, 1, 1).to(device)\n",
    "#TODO: use generator model to generate fake image \n",
    "fake_images = G(noise)\n",
    "print(fake_images.shape)\n",
    "#TODO: visualize the fake images by function show_images\n",
    "show_images(fake_images.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "## Discriminator and Generator Losses\n",
    "\n",
    "Now we need to calculate the losses for both types of adversarial networks.\n",
    "\n",
    "### Discriminator Losses\n",
    "\n",
    "> * For the discriminator, the total loss is the sum of the losses for real and fake images, `d_loss = d_real_loss + d_fake_loss`. \n",
    "* Remember that we want the discriminator to output 1 for real images and 0 for fake images, so we need to set up the losses to reflect that.\n",
    "\n",
    "\n",
    "### Generator Loss\n",
    "\n",
    "The generator loss will look similar only with flipped labels. The generator's goal is to get the discriminator to *think* its generated images are *real*.\n",
    "\n",
    "#### Exercise: Complete real and fake loss functions\n",
    "\n",
    "**You may choose to use either cross entropy or a least squares error loss to complete the following `real_loss` and `fake_loss` functions. We also encourage students to use the loss function in other related papers as a bonus item. If you use it, please include a citation in the report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODOï¼šComplete the loss function for training GAN\n",
    "real_loss_function = nn.BCELoss()\n",
    "fake_loss_function = nn.BCELoss()\n",
    "def Real_loss(preds,targets):\n",
    "    '''\n",
    "       Calculates how close discriminator outputs are to being real.\n",
    "       param, D_out: discriminator logits\n",
    "       return: real loss\n",
    "    '''\n",
    "    loss = real_loss_function(preds,targets)\n",
    "    return loss\n",
    "def Fake_loss(preds,targets):\n",
    "    '''\n",
    "       Calculates how close discriminator outputs are to being fake.\n",
    "       param, D_out: discriminator logits\n",
    "       return: fake loss\n",
    "    '''\n",
    "    loss = fake_loss_function(preds,targets)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Optimizers\n",
    "\n",
    "#### Exercise: Define optimizers for your Discriminator (D) and Generator (G)\n",
    "\n",
    "Define optimizers for your models with appropriate hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create optimizers for the discriminator D and generator G\n",
    "#Define your learning rate\n",
    "lr=0.0002\n",
    "opt_d = torch.optim.Adam(D.parameters(), lr=lr, betas = (0.5,0.999))\n",
    "opt_g = torch.optim.Adam(G.parameters(), lr=lr, betas = (0.5,0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Save the generated images\n",
    "This code can help you save images generated from Generator G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##Define your save path.\n",
    "sample_dir = 'generated'\n",
    "os.makedirs(sample_dir, exist_ok=True)\n",
    "def save_samples(index, latent_tensors, generator, show=True):\n",
    "    fake_images = generator(latent_tensors)\n",
    "    fake_fname = 'generated-images-{0:0=4d}.png'.format(index)\n",
    "    save_image(denorm(fake_images), os.path.join(sample_dir, fake_fname), nrow=8)\n",
    "    print('Saving', fake_fname)\n",
    "    if show:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(fake_images.cpu().detach(), nrow=8).permute(1, 2, 0))\n",
    "        plt.show()\n",
    "fixed_latent = torch.randn(64, latent_size, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Training GAN to generate anime faces\n",
    "Training will involve alternating between training the discriminator and the generator. You'll use your functions `real_loss` and `fake_loss` to help you calculate the discriminator losses.\n",
    "\n",
    "* You should train the discriminator by alternating on real and fake images\n",
    "* Then the generator, which tries to trick the discriminator and should have an opposing loss function\n",
    "\n",
    "\n",
    "#### Saving Samples\n",
    "\n",
    "You've been given some code to save some generated \"fake\" samples.\n",
    "\n",
    "#### Exercise: Complete the training function\n",
    "\n",
    "Keep in mind that, if you've moved your models to GPU, you'll also have to move any model inputs to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Complete the training function\n",
    "from sklearn.metrics import accuracy_score\n",
    "losses_g = []\n",
    "losses_d = []\n",
    "real_scores = []\n",
    "fake_scores = []\n",
    "def train(D, G, d_optimizer, g_optimizer, epochs=1):\n",
    "    iter_count = 0\n",
    "    start_idx=1\n",
    "    D.train()\n",
    "    G.train()\n",
    "    for epoch in range(epochs):\n",
    "        for real_images in tqdm(trainloader):\n",
    "            with torch.set_grad_enabled(True):\n",
    "                real_images=real_images.to(device)\n",
    "                real_batch_size = real_images.shape[0]\n",
    "                # -----------------------------------------------\n",
    "                #         YOUR CODE HERE: TRAIN THE NETWORKS\n",
    "                # -----------------------------------------------\n",
    "                # 1. Train the discriminator on real and fake images\n",
    "                d_optimizer.zero_grad()\n",
    "                # Pass real images through discriminator\n",
    "                d_real_out = D(real_images)\n",
    "                real_labels=torch.ones((real_batch_size, 1)).to(device)\n",
    "                real_loss = Real_loss(d_real_out,real_labels)\n",
    "                #real_score = accuracy_score(real_labels.cpu().detach().numpy().flatten(), [0 if d < 0.5 else 1 for d in d_real_out.cpu().detach().numpy().flatten()])\n",
    "                real_score = torch.mean(d_real_out).item()\n",
    "                # Generate fake images\n",
    "                noise = torch.randn(real_batch_size, latent_size, 1, 1).to(device)\n",
    "                fake_images = G(noise)\n",
    "\n",
    "                # Pass fake images through discriminator\n",
    "                d_fake_out = D(fake_images)\n",
    "                fake_labels=torch.zeros((real_batch_size, 1)).to(device)\n",
    "                fake_loss = Fake_loss(d_fake_out,fake_labels)\n",
    "                #fake_score = accuracy_score(fake_labels.cpu().detach().numpy().flatten(), [0 if d < 0.5 else 1 for d in d_fake_out.cpu().detach().numpy().flatten()])\n",
    "                fake_score = torch.mean(d_fake_out).item()\n",
    "                # Update discriminator weights\n",
    "                loss_d = real_loss + fake_loss\n",
    "                loss_d.backward()\n",
    "                d_optimizer.step()\n",
    "\n",
    "\n",
    "                ## 2. Train the generator with an adversarial loss\n",
    "                g_optimizer.zero_grad()\n",
    "                # Generate fake images\n",
    "                noise = torch.randn(real_batch_size, latent_size, 1, 1).to(device)\n",
    "                fake_images = G(noise)\n",
    "                # Try to fool the discriminator\n",
    "                d_fake_out = D(fake_images)\n",
    "                # The label is set to 1(real-like) to fool the discriminator\n",
    "                flipped_labels=torch.ones((real_batch_size, 1)).to(device)\n",
    "                loss_g = Real_loss(d_fake_out,flipped_labels)\n",
    "                # Update generator weights\n",
    "                loss_g.backward()\n",
    "                g_optimizer.step()\n",
    "\n",
    "\n",
    "        losses_g.append(loss_g.item())\n",
    "        losses_d.append(loss_d.item())\n",
    "        real_scores.append(real_score)\n",
    "        fake_scores.append(fake_score)\n",
    "        # Log losses & scores (last batch)\n",
    "        print(\"Epoch [{}/{}], loss_g: {:.4f}, loss_d: {:.4f}, real_score: {:.4f}, fake_score: {:.4f}\".format(\n",
    "        epoch+1, epochs, loss_g, loss_d, real_score, fake_score))\n",
    "\n",
    "        # Save generated images\n",
    "        save_samples(epoch+start_idx, fixed_latent,G, show=True)\n",
    "            \n",
    "        state_dis = {'dis_model': D.state_dict(), 'epoch': epoch}\n",
    "        state_gen = {'gen_model': G.state_dict(), 'epoch': epoch}\n",
    "        if not os.path.isdir('checkpoint'):\n",
    "            os.mkdir('checkpoint') \n",
    "        torch.save(state_dis, 'checkpoint/'+'D__'+str(epoch+1)) #each epoch\n",
    "        torch.save(state_gen, 'checkpoint/'+'G__'+str(epoch+1)) #each epoch\n",
    "#Train the GAN\n",
    "train(D,G,opt_d,opt_g,epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##Visualize your loss curve of D and G\n",
    "fig, ax = plt.subplots()\n",
    "plt.plot(losses_d, label='Discriminator', alpha=0.5)\n",
    "plt.plot(losses_g, label='Generator', alpha=0.5)\n",
    "plt.title(\"Training Losses\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question1: What do you notice about your generated samples and how might you improve this model?\n",
    "When you answer this question, consider the following factors:\n",
    "* Model size; larger models have the opportunity to learn more features in a data feature space\n",
    "* Optimization strategy; optimizers and number of epochs affect your final result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "* Increasing the number of epochs on its own doesn't make generated photos better. In one experiment after the 79th epoch the discriminator loss skyrocketed to the 100 and the generator loss plummeted to the 0 and the training virtually stopped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Question2: How does the training loss of the generator and the discriminator change during your training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Answer: (Write your answer in this cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook. Save the notebook file as \"final_project_StudentNumber_StudentName.ipynb\". Include the generated images in your submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}